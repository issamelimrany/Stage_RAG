{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3641f304-4da8-47ac-ad8f-720a51347b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-text-splitters) (0.2.19)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (0.1.85)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (8.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (3.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain-text-splitters) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-text-splitters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef5c258-f921-4c37-9e3d-211441cf42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b09f1c2-45b1-4b2a-9738-8b1395b3c526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file from: Downloads/sample html file download.html\n",
      "HTML content read successfully: <html>\n",
      "<head></head>\n",
      "<body><h1>Hi</h1></body>\n",
      "</html>...\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "import os\n",
    "\n",
    "def split_html_from_file(file_path):\n",
    "    try:\n",
    "        print(f\"Reading file from: {file_path}\")\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            html_content = file.read()\n",
    "\n",
    "        print(f\"HTML content read successfully: {html_content[:100]}...\")\n",
    "\n",
    "        headers_to_split_on = [\n",
    "            (\"h1\", \"Header 1\"),\n",
    "            (\"h2\", \"Header 2\"),\n",
    "            (\"h3\", \"Header 3\"),\n",
    "        ]\n",
    "\n",
    "        html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "        html_header_splits = html_splitter.split_text(html_content)\n",
    "\n",
    "        # Print the results\n",
    "        for document in html_header_splits:\n",
    "            print(f\"Content: {document.page_content}\")\n",
    "            print(f\"Metadata: {document.metadata}\")\n",
    "            print()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Example usage with a file path\n",
    "file_path = 'Downloads/sample html file download.html'\n",
    "split_html_from_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f88a073-524d-4c72-9c86-c36ed06e36f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML Content:\n",
      "<html>\n",
      "<head></head>\n",
      "<body><h1>Hi</h1></body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "# Define headers to split on\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "# Initialize the splitter\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# Path to your local HTML file\n",
    "file_path = \"Downloads/sample html file download.html\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "    print(\"HTML Content:\")\n",
    "    print(html_content)\n",
    "\n",
    "html_header_splits = html_splitter.split_text(html_content)\n",
    "\n",
    "# Print out the results\n",
    "for doc in html_header_splits:\n",
    "    print(f\"Page Content: {doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b55bfb45-ae8f-49be-ad61-c6cdcec4ed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Hi')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "# HTML content from your file (replace this with your actual HTML content)\n",
    "html_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "   <div>\n",
    "    <h1>Hi</h1>\n",
    "   </div> \n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "# Define headers to split on\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(html_content)\n",
    "html_header_splits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f32f648-ebfc-4ed3-8d98-1c8ab2a7a5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "        <h1>Hi</h1>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec21b245-c199-437e-a281-8a77300c8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section: Introduction \n",
      " This section introduces the topic.\n",
      "Metadata: {'Header 1': 'Introduction'}\n",
      "-------------------\n",
      "Section: Methods \n",
      " Details about the experimental methods used.\n",
      "Metadata: {'Header 1': 'Methods'}\n",
      "-------------------\n",
      "Section: Results \n",
      " Summary of the key results obtained.\n",
      "Metadata: {'Header 1': 'Results'}\n",
      "-------------------\n",
      "Section: Discussion \n",
      " Interpretation of results and implications.\n",
      "Metadata: {'Header 1': 'Discussion'}\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "from langchain_text_splitters import HTMLSectionSplitter\n",
    "\n",
    "# Define headers and other structural elements to split on\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "    (\"h4\", \"Header 4\"),\n",
    "]\n",
    "\n",
    "# Path to the XSLT file\n",
    "xslt_path = \"Downloads/convert_to_header.xslt\"\n",
    "\n",
    "# Example HTML content with <span> elements to be transformed\n",
    "html_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Example HTML Document</title>\n",
    "</head>\n",
    "<body>\n",
    "    <span class=\"section-title\">Introduction</span>\n",
    "    <p>This section introduces the topic.</p>\n",
    "    \n",
    "    <span class=\"section-title\">Methods</span>\n",
    "    <p>Details about the experimental methods used.</p>\n",
    "    \n",
    "    <span class=\"section-title\">Results</span>\n",
    "    <p>Summary of the key results obtained.</p>\n",
    "    \n",
    "    <span class=\"section-title\">Discussion</span>\n",
    "    <p>Interpretation of results and implications.</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Apply XSLT transformation to preprocess HTML content\n",
    "xslt = etree.parse(xslt_path)\n",
    "transform = etree.XSLT(xslt)\n",
    "transformed_html = transform(etree.fromstring(html_content))\n",
    "\n",
    "# Initialize HTMLSectionSplitter with the XSLT path and headers to split on\n",
    "html_splitter = HTMLSectionSplitter(headers_to_split_on=headers_to_split_on, xslt_path=xslt_path)\n",
    "\n",
    "# Convert the transformed HTML back to a string\n",
    "transformed_html_string = etree.tostring(transformed_html, pretty_print=True).decode()\n",
    "\n",
    "# Split transformed HTML content into sections\n",
    "html_sections = html_splitter.split_text(transformed_html_string)\n",
    "\n",
    "# Print out each section and its metadata\n",
    "for section in html_sections:\n",
    "    print(f\"Section: {section.page_content}\")\n",
    "    print(f\"Metadata: {section.metadata}\")\n",
    "    print(\"-------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5aab7e4c-ac66-4abf-8fd1-885f7ace997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 260, which is longer than the specified 100\n",
      "Created a chunk of size 106, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\n",
      "Metadata: {'chapter': 1, 'paragraph': 1}\n",
      "--------------------\n",
      "\n",
      "Chunk 2:\n",
      "However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters.\n",
      "Metadata: {'chapter': 1, 'paragraph': 1}\n",
      "--------------------\n",
      "\n",
      "Chunk 3:\n",
      "\"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that Netherfield Park is let at last?\"\n",
      "Metadata: {'chapter': 1, 'paragraph': 1}\n",
      "--------------------\n",
      "\n",
      "Chunk 4:\n",
      "Mr. Bennet replied that he had not.\n",
      "Metadata: {'chapter': 1, 'paragraph': 1}\n",
      "--------------------\n",
      "\n",
      "Chunk 5:\n",
      "\"But it is,\" returned she; \"for Mrs. Long has just been here, and she told me all about it.\"\n",
      "Metadata: {'chapter': 1, 'paragraph': 1}\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Define the Novel Excerpt\n",
    "novel_excerpt = \"\"\"\n",
    "It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\n",
    "\n",
    "However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters.\n",
    "\n",
    "\"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that Netherfield Park is let at last?\"\n",
    "\n",
    "Mr. Bennet replied that he had not.\n",
    "\n",
    "\"But it is,\" returned she; \"for Mrs. Long has just been here, and she told me all about it.\"\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Import and Configure CharacterTextSplitter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",  # Split on double newline\n",
    "    chunk_size=100,    # Desired chunk size in characters\n",
    "    chunk_overlap=20,  # Number of overlapping characters between chunks\n",
    "    length_function=len,  # Function to measure chunk length (default is len)\n",
    "    is_separator_regex=False  # Whether the separator is a regex pattern\n",
    ")\n",
    "\n",
    "# Step 4: Split the Document and Add Metadata\n",
    "metadata = [{\"chapter\": 1, \"paragraph\": i + 1} for i in range(len(novel_excerpt.split(\"\\n\\n\")))]\n",
    "documents = text_splitter.create_documents([novel_excerpt], metadatas=metadata)\n",
    "\n",
    "# Step 5: Print the Split Chunks with Metadata\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Chunk {i + 1}:\\n{doc.page_content}\\nMetadata: {doc.metadata}\\n{'-' * 20}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04d209b5-a477-45b1-a678-941deb0e81b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1:\n",
      "Content:\n",
      "The purpose of this document is to demonstrate the usage of MarkdownHeaderTextSplitter.\n",
      "\n",
      "Metadata:\n",
      "{'Header 1': 'Introduction', 'Header 2': 'Purpose'}\n",
      "\n",
      "Split 2:\n",
      "Content:\n",
      "- Splits Markdown based on headers.\n",
      "- Retains header information in metadata.\n",
      "\n",
      "Metadata:\n",
      "{'Header 1': 'Introduction', 'Header 2': 'Features'}\n",
      "\n",
      "Split 3:\n",
      "Content:\n",
      "This is an example section within the Markdown document.\n",
      "\n",
      "Metadata:\n",
      "{'Header 1': 'Introduction', 'Header 2': 'Features', 'Header 3': 'Example Section'}\n",
      "\n",
      "Split 4:\n",
      "Content:\n",
      "In conclusion, MarkdownHeaderTextSplitter is useful for organizing and processing Markdown content.\n",
      "\n",
      "Metadata:\n",
      "{'Header 1': 'Introduction', 'Header 2': 'Conclusion'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "# Example Markdown document\n",
    "markdown_document = \"\"\"\n",
    "# Introduction\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The purpose of this document is to demonstrate the usage of MarkdownHeaderTextSplitter.\n",
    "\n",
    "## Features\n",
    "\n",
    "- Splits Markdown based on headers.\n",
    "- Retains header information in metadata.\n",
    "\n",
    "### Example Section\n",
    "\n",
    "This is an example section within the Markdown document.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In conclusion, MarkdownHeaderTextSplitter is useful for organizing and processing Markdown content.\n",
    "\"\"\"\n",
    "\n",
    "# Headers to split on\n",
    "headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n",
    "\n",
    "# Initialize MarkdownHeaderTextSplitter\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# Split Markdown document into chunks with headers\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "\n",
    "# Display the results\n",
    "for idx, split in enumerate(md_header_splits):\n",
    "    print(f\"Split {idx + 1}:\")\n",
    "    print(f\"Content:\\n{split.page_content}\\n\")\n",
    "    print(f\"Metadata:\\n{split.metadata}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f29da6-7715-4275-9c39-00dda679abbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
