{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#**Creating YouTube transcripts with OpenAI's Whisper model**\n","\n","###**Note: For faster performance set your runtime to \"GPU\"**\n","*Click on \"Runtime\" in the menu and click \"Change runtime type\". Select \"GPU\".*\n","\n","\n","**Step 1.** Follow the instructions in each block and select the options you want\n","<br>\n","**Step 2.** Get the url of the video you want to transcribe\n","<br>\n","**Step 3.** Refresh the folder on the left and download your transcript\n","<br>\n","**Step 4.** Go to your YouTube account and upload the transcript to the video it came from and use \"autosync.\"\n","\n","\n","<br>\n","\n","\n","\n","---\n","\n","\n","**What is this?**\n","<br>\n","This is a Python notebook that creates a transcript from a YouTube url using OpenAI's Whisper transcription model that you can then upload to YouTube using the autosync feature to create captions.\n","<br>  \n","**What is OpenAI's Whisper model?**\n","<br>\n","Whisper is an automatic speech recognition (ASR) neural net created by OpenAI that transcribes audio at close to human level.\n","<br>\n","<br>\n","**Why use this?**\n","<br>\n","The quality of the OpenAI Whisper model is amazing (I am slightly biased, but seriously, check it out.) You can also use it to transcribe in other languages.\n","<br>\n","<br>\n","**What do the different model sizes do?**\n","<br>\n","Each model size has an improvement in quality â€“ especially with different languages. I've found that for a YouTube video with clear speech, the base model works really well. If you see transcription errors, you can try a larger model.\n","<br>\n","<br>\n","**Do I need timestamps?**\n","<br>\n","Nope. YouTube's autosync function will match the text to the spoken words and syncs up really well. All you need is each spoken sentence in a .txt file.\n","<br>\n","<br>\n","**How do I do this?**\n","<br>\n","Just follow each step. If you've never used Colab of a Python notebook, don't panic. It's super easy and runs in the cloud.\n","<br>\n","<br>\n","**Does this cost anything to use?**\n","<br>\n","Nope. You can use Colab for free and Whisper is an open source model.\n","<br>\n","<br>\n","[Tips for creating a YouTube transcript file](https://support.google.com/youtube/answer/2734799?hl=en)\n","<br>\n","[Information on OpenAI's Whisper model](https://openai.com/blog/whisper/)\n","<br>\n","[OpenAI's Whisper GitHub page](https://github.com/openai/whisper)\n","<br>\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"Qvz5JoKjwKAu"}},{"cell_type":"code","source":["\"\"\"\n","1. Click the start button in the upper left side of this block to load the necessary libraries\n","\n","You will need to run this every time you reload this notebook.\n","\"\"\"\n","\n","\n","!pip install git+https://github.com/openai/whisper.git\n","!sudo apt update && sudo apt install ffmpeg\n","!pip install librosa\n","!pip install yt-dlp\n","\n","import whisper\n","import time\n","import librosa\n","import re\n","import yt_dlp\n"],"metadata":{"id":"j6svgIwL1a-J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723641435851,"user_tz":-60,"elapsed":20384,"user":{"displayName":"ousama ahamri","userId":"08690758008121141035"}},"outputId":"0475f4d2-90bd-4e4c-bf82-6a522fde1bc4","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: youtube_dl in /usr/local/lib/python3.10/dist-packages (2021.12.17)\n","Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-n2pg77w2\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-n2pg77w2\n","  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.26.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.5)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.3.0)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.7.0)\n","Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.15.4)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.32.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2024.6.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.6.20)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Ign:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy Release\n","Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4.0)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.7.4)\n"]}]},{"cell_type":"code","source":["\"\"\"\n","2. Select the model you want to use.\n","\n","Base works really well so it's the default.\n","\n","(For multilingual, remove \".en\" from the model name.)\n","\n","Click the run button after you've made your choice (or left it at default.)\n","\"\"\"\n","\n","# model = whisper.load_model(\"tiny.en\")\n","model = whisper.load_model(\"base.en\")\n","# model = whisper.load_model(\"small.en\")\n","# model = whisper.load_model(\"medium.en\")\n","# model = whisper.load_model(\"large\")"],"metadata":{"id":"9oRA4UIe104O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","3. Click the run button and input your YouTube URL in the box below then click enter.\n","\n","The video will be loaded and the audio extracted (this is usually the longest part of the process.)\n","\n","Your transcript will appear in the folder on the left (you may have to refresh the folder to see it.)\n","\n","You can download the file when it's completed and upload it on your video's detail page using \"autosync.\"\n","\"\"\"\n","\n","# This will prompt you for a YouTube video URL\n","url = input(\"Enter a YouTube video URL: \")\n","\n","# Create a youtube-dl options dictionary\n","ydl_opts = {\n","    # Specify the format as bestaudio/best\n","    'format': 'bestaudio/best',\n","    # Specify the post-processor as ffmpeg to extract audio and convert to mp3\n","    'postprocessors': [{\n","        'key': 'FFmpegExtractAudio',\n","        'preferredcodec': 'mp3',\n","        'preferredquality': '192',\n","    }],\n","    # Specify the output filename as the video title\n","    'outtmpl': '%(title)s.%(ext)s',\n","}\n","\n","# Download the video and extract the audio\n","with yt_dlp.YoutubeDL(ydl_opts) as ydl:  # Use yt-dlp.YoutubeDL\n","    ydl.download([url])\n","\n","# Get the path of the file\n","file_path = ydl.prepare_filename(ydl.extract_info(url, download=False))\n","file_path = file_path.replace('.webm', '.mp3')\n","file_path = file_path.replace('.m4a', '.mp3')\n","\n","# Get the duration\n","duration = librosa.get_duration(filename=file_path)\n","start = time.time()\n","result = model.transcribe(file_path)\n","end = time.time()\n","seconds = end - start\n","\n","print(\"Video length:\", duration, \"seconds\")\n","print(\"Transcription time:\", seconds)\n","\n","# Split result[\"text\"]  on !,? and . , but save the punctuation\n","sentences = re.split(\"([!?.])\", result[\"text\"])\n","\n","# Join the punctuation back to the sentences\n","sentences = [\"\".join(i) for i in zip(sentences[0::2], sentences[1::2])]\n","text = \"\\n\\n\".join(sentences)\n","for s in sentences:\n","  print(s)\n","\n","# Save the file as .txt\n","name = \"\".join(file_path) + \".txt\"\n","with open(name, \"w\") as f:\n","  f.write(text)\n","\n","print(\"\\n\\n\", \"-\"*100, \"\\n\\nYour transcript is here:\", name)"],"metadata":{"id":"JmbHC2-S33Kl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723641655558,"user_tz":-60,"elapsed":35923,"user":{"displayName":"ousama ahamri","userId":"08690758008121141035"}},"outputId":"4c4fec19-c21a-4f3c-cf8a-09946d74ba27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter a YouTube video URL: https://www.youtube.com/watch?v=P9cLmFGWfIw\n","[youtube] Extracting URL: https://www.youtube.com/watch?v=P9cLmFGWfIw\n","[youtube] P9cLmFGWfIw: Downloading webpage\n","[youtube] P9cLmFGWfIw: Downloading ios player API JSON\n","[youtube] P9cLmFGWfIw: Downloading web creator player API JSON\n","[youtube] P9cLmFGWfIw: Downloading player 410a4f15\n","[youtube] P9cLmFGWfIw: Downloading m3u8 information\n","[info] P9cLmFGWfIw: Downloading 1 format(s): 251\n","[download] Destination: Data Science in 4 Minutesï¼š Quick High Level Overview.webm\n","[download] 100% of    2.66MiB in 00:00:00 at 3.05MiB/s   \n","[ExtractAudio] Destination: Data Science in 4 Minutesï¼š Quick High Level Overview.mp3\n","Deleting original file Data Science in 4 Minutesï¼š Quick High Level Overview.webm (pass -k to keep)\n","[youtube] Extracting URL: https://www.youtube.com/watch?v=P9cLmFGWfIw\n","[youtube] P9cLmFGWfIw: Downloading webpage\n","[youtube] P9cLmFGWfIw: Downloading ios player API JSON\n","[youtube] P9cLmFGWfIw: Downloading web creator player API JSON\n","[youtube] P9cLmFGWfIw: Downloading m3u8 information\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-10-0edae3c8832d>:46: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n","\tThis alias will be removed in version 1.0.\n","  duration = librosa.get_duration(filename=file_path)\n"]},{"output_type":"stream","name":"stdout","text":["Video length: 216.01525 seconds\n","Transcription time: 12.835594177246094\n"," Hi, this is Jeff Heaton.\n"," I'm going to tell you what data science is in four minutes, or at least try.\n"," I better get going.\n"," First up, data.\n"," You can't have science without data.\n"," Maybe you have a little, maybe you have a lot, but you've got to have data.\n"," Often your data will be in a tabular firm like this.\n"," Think Microsoft Excel.\n"," You've got columns.\n"," You'd like to predict one of them.\n"," Maybe you would like to predict the acceleration of a car based on these other parameters.\n"," You know the acceleration for a lot of these cars, but maybe there's some cars where you don't know the acceleration.\n"," You can train a model to predict that acceleration based on the ones that you already know.\n"," This is supervised learning.\n"," If you're trying to predict a number, it's regression.\n"," If you're trying to predict a class or a category or a type of car, it is classification.\n"," There's also unsupervised learning.\n"," Maybe you don't know the acceleration for any car.\n"," In this case, you take the values that you do have and try to cluster them.\n"," Your unsupervised learning is going to look like this.\n"," You're going to have clusters that those rows fall into.\n"," Maybe you'll have the colors or maybe you won't, depending on the algorithm that you're using.\n"," It's probably up to you to assign which of those clusters new items most closely aligned with.\n"," Another important point is deciding how many clusters there are ahead of time.\n"," Maybe you decide it.\n"," Maybe the algorithm does.\n"," It just depends on the algorithm.\n"," Unsupervised and supervised learning are definitely the two biggest categories in data science.\n"," However, new categories are coming up all the time.\n"," This is not the only way that this can be done.\n"," Most of these algorithms, at least for supervised learning, are all about fitting a line to the actual data.\n"," The actual data on the top one is the black line, which is very noisy usually.\n"," The red line is the model that you're developing that as you train it gets closer and closer to the actual values, but you don't want it to be as jagged as the actual values, at least usually, or you will be in danger of overfitting.\n"," Overfitting is one of your arch enemies as a data scientist.\n"," You must prevent your models from overfitting.\n"," There's other arch enemies as well, but it is one of the big ones.\n"," Think of overfitting as like memorization.\n"," If you're given a sample exam and you study just that sample exam and over and over and eventually you get 100% on the sample exam, will you pass the real exam?\n"," Probably not.\n"," There's underfitting too.\n"," Underfitting occurs when the model type that you've chosen, such as an RBF, a Gaussian process, decision tree random forest, all these ones that you see across the very top of your screen, the columns are model types.\n"," The rows are types of data.\n"," You can see that the models themselves, the curved regions of those colors, they don't always fit the data just perfectly.\n"," That is called bias error.\n"," Your model simply cannot fit to the type of data that you have.\n"," The solution to this is to use an ensemble where you use several columns to represent your data together.\n"," But how do you get a better model of your data?\n"," Well, there's many ways to do that, but one of the most common is something called feature engineering.\n"," Feature engineering is where you create additional calculated columns in your data where maybe you take something like the acceleration and calculate that together with the size of the engine, maybe a ratio, to calculate an efficiency column that you add to this and pass it in with all your other data.\n"," There you go.\n"," Data science in four minutes.\n"," Of course, there's a lot more to this field.\n"," You can learn about that by subscribing to my YouTube channel.\n"," Thank you for watching.\n"," Thank you.\n","\n","\n"," ---------------------------------------------------------------------------------------------------- \n","\n","Your transcript is here: Data Science in 4 Minutesï¼š Quick High Level Overview.mp3.txt\n"]}]}]}