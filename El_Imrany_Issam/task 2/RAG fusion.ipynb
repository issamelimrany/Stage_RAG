{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c51152-c2a6-45fa-a17c-8400046989e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n",
      "Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved document: Advancements in quantum computing\n",
      "Source: research_paper\n",
      "\n",
      "Retrieved document: AI and its impact on society\n",
      "Source: tech_journal\n",
      "\n",
      "Retrieved document: Climate change mitigation strategies\n",
      "Source: science_mag\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "\n",
    "# Set OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = 'your code'\n",
    "\n",
    "# Initialize components\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(embedding_function=embeddings)\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Create documents\n",
    "documents = [\n",
    "    Document(page_content=\"AI and its impact on society\", metadata={\"source\": \"tech_journal\"}),\n",
    "    Document(page_content=\"Climate change mitigation strategies\", metadata={\"source\": \"science_mag\"}),\n",
    "    Document(page_content=\"Advancements in quantum computing\", metadata={\"source\": \"research_paper\"}),\n",
    "]\n",
    "\n",
    "# Add documents to vectorstore and create BM25 index\n",
    "vectorstore.add_documents(documents)\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "\n",
    "def rag_fusion(query, k=10):\n",
    "    # Generate query variations\n",
    "    query_variations = [\n",
    "        query,\n",
    "        f\"In the context of {query}, what are the key points?\",\n",
    "        f\"Explain {query} in simple terms\",\n",
    "    ]\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Retrieve documents for each query variation\n",
    "    for q in query_variations:\n",
    "        vector_results = vectorstore.similarity_search(q, k=k)\n",
    "        bm25_results = bm25_retriever.get_relevant_documents(q)[:k]\n",
    "        all_results.extend(vector_results)\n",
    "        all_results.extend(bm25_results)\n",
    "    \n",
    "    # Deduplicate results based on content\n",
    "    unique_results = []\n",
    "    seen_content = set()\n",
    "    for doc in all_results:\n",
    "        if doc.page_content not in seen_content:\n",
    "            unique_results.append(doc)\n",
    "            seen_content.add(doc.page_content)\n",
    "    \n",
    "    # Rerank results using reciprocal rank fusion\n",
    "    rrf_scores = [0] * len(unique_results)\n",
    "    for i, doc in enumerate(all_results):\n",
    "        if doc.page_content in seen_content:\n",
    "            idx = next(i for i, d in enumerate(unique_results) if d.page_content == doc.page_content)\n",
    "            rrf_scores[idx] += 1 / (i + 1)\n",
    "    \n",
    "    # Sort results by RRF score\n",
    "    sorted_results = sorted(zip(unique_results, rrf_scores), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return [doc for doc, score in sorted_results[:k]]\n",
    "\n",
    "# Perform a query\n",
    "query = \"What are the latest technological advancements?\"\n",
    "fusion_results = rag_fusion(query)\n",
    "\n",
    "for doc in fusion_results:\n",
    "    print(f\"Retrieved document: {doc.page_content}\")\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
